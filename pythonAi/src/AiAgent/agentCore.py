'''
# å¯¼å…¥å¿…è¦çš„åº“
# ä½¿ç”¨æ–°ç‰ˆæ¨¡å—ç»“æ„
'''

from langchain_community.chat_models import ChatZhipuAI

from langchain.agents import create_agent


from langchain_core.messages import HumanMessage, AIMessage, SystemMessage,ToolMessage


import os 
from memory import ConversationMemory  #  å¯¼å…¥å¯¹è¯ç®¡ç†ç±»

from tools import calculator, search_Weather,get_current_time,query_document #å¯¼å…¥å·¥å…·
import time


    
# 1. è®¾ç½®ä½ çš„API Key (è¿™é‡Œæ˜¯å”¯ä¸€éœ€è¦ä¿®æ”¹çš„åœ°æ–¹)

#day2 æŠŠæ­¥éª¤å°è£…æˆå‡½æ•°ï¼Œåœ¨mainé‡Œè°ƒç”¨
def get_api_key():
    """å®‰å…¨åœ°è·å–APIå¯†é’¥ã€‚å¦‚æœæœªè®¾ç½®ï¼Œåˆ™æŠ›å‡ºå¼‚å¸¸ã€‚"""
    zhipu_api_key = os.getenv("ZHIPUAI_API_KEY")
    if not zhipu_api_key:
        # æ”¹ä¸ºæŠ›å‡ºå¼‚å¸¸ï¼Œè€Œéç›´æ¥é€€å‡º
        raise ValueError("âŒ æœªæ‰¾åˆ°ç¯å¢ƒå˜é‡ ZHIPUAI_API_KEYã€‚è¯·åœ¨ç»ˆç«¯æ‰§è¡Œ: export ZHIPUAI_API_KEY='ä½ çš„å¯†é’¥'")
    return zhipu_api_key


def create_ai_agent(api_key):
    
    """æ ¹æ®ç»™å®šçš„APIå¯†é’¥ï¼Œåˆ›å»ºå¹¶è¿”å›ä¸€ä¸ªAI Agentå®ä¾‹ï¼ˆæ¨¡å‹ï¼‰ã€‚éœ€è¦æ‰‹åŠ¨ç®¡ç†ReActæµç¨‹"""
    print("ğŸ§  æ­£åœ¨åˆå§‹åŒ–AI Agent...")
    llm = ChatZhipuAI(
        model="glm-4",
        temperature=0.1,
        streaming=True,
        api_key=api_key,
    )
    
    tools = [calculator, search_Weather,get_current_time,query_document]  
    # llm_with_tools = llm.bind_tools(tools)  #æ·»åŠ å¹¶ç»‘å®šå·¥å…·ç»™æ¨¡å‹
    # return llm_with_tools
    '''
    ä½¿ç”¨create_agentåˆ›å»ºè‡ªåŠ¨ç®¡ç†ReActçš„agent
    '''

   # Prompt ä½œä¸º state_modifier ä¼ ï¼ˆå­—ç¬¦ä¸²æˆ– PromptTemplate éƒ½è¡Œï¼‰
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„AIåŠ©æ‰‹ï¼Œèƒ½ä½¿ç”¨å·¥å…·è§£å†³é—®é¢˜ã€‚
è¯·ä¸¥æ ¼æŒ‰ç…§ ReAct æ ¼å¼æ€è€ƒï¼šå¹¶ä¸”æ¯ä¸€æ­¥éƒ½æ‰“å°å‡ºæ¥
Thought: å…ˆæ€è€ƒä¸‹ä¸€æ­¥è¯¥åšä»€ä¹ˆ
Action: å¦‚æœéœ€è¦ï¼Œè°ƒç”¨å·¥å…·
Observation: è§‚å¯Ÿå·¥å…·ç»“æœ
Final Answer: ç»™å‡ºç”¨æˆ·æœ€ç»ˆå›ç­”"""
    agent = create_agent(
        model=llm,
        tools=tools,
       system_prompt =system_prompt, 
    )
    return agent
    

# åœ¨è®°å¿†æ¨¡å—éƒ¨åˆ†ï¼Œæ·»åŠ ä»¥ä¸‹å‡½æ•°ï¼ˆæ”¾åœ¨ get_memory å‡½æ•°åé¢å³å¯ï¼‰  æ·»åŠ å‚æ•°memory_objï¼Œ ç”¨ä»–æ¥ç®¡ç†æ¶ˆæ¯æ“ä½œ
def get_memory_as_langchain_messages(memory_obj):
    """å°†å†…éƒ¨è®°å¿†æ ¼å¼è½¬æ¢ä¸ºLangChainçš„Messageå¯¹è±¡åˆ—è¡¨"""
    langchain_messages = []
    for msg in memory_obj.getAllMemoryList():  
        if msg["role"] == "user":
            langchain_messages.append(HumanMessage(content=msg["content"]))
        elif msg["role"] == "assistant":
            langchain_messages.append(AIMessage(content=msg["content"]))
        elif msg["role"] == "system":
            langchain_messages.append(SystemMessage(content=msg["content"]))
        elif msg["role"] == "tool":
            # æ³¨æ„ï¼šä½ çš„å†…å­˜ä¸­å­˜å‚¨çš„æ˜¯å­—å…¸ï¼Œéœ€è¦æå–ä¿¡æ¯æ„é€ ToolMessage 
            # å‡è®¾ä½ å­˜å‚¨æ—¶æ ¼å¼æ˜¯ï¼š{"role": "tool", "content": "...", "name": "...", "tool_call_id": "..."}
            # ä½ éœ€è¦æ ¹æ®å®é™…å­˜å‚¨çš„å­—æ®µæ¥è°ƒæ•´
            tool_message = ToolMessage(
                content=msg.get("content", ""),
                name=msg.get("name", ""),  
                tool_call_id=msg.get("tool_call_id", "")  
            )
            langchain_messages.append(tool_message)
    return langchain_messages
    #è¿”å›çš„æ˜¯ä¸€ä¸ªå…¨æ˜¯langchianå¯¹è±¡çš„æ¶ˆæ¯åˆ—è¡¨ï¼Œå°†æ•´ä¸ªå¯¹è¯å†…å®¹å‘é€ç»™æ¨¡å‹ï¼Œ ä½¿å¾—æ¨¡å‹æœ‰è®°å¿†


#æ‰‹åŠ¨ç®¡ç†ReAct  éœ€è¦æ‰‹åŠ¨å­˜å‚¨æ¶ˆæ¯ï¼Œå·¥å…·æ¶ˆæ¯ï¼Œ ç”¨æˆ·æ¶ˆæ¯ï¼Œ AIæ¶ˆæ¯
def run_chat_loop(agent_brain,memory_obj): #æ·»åŠ å‚æ•°memory_objï¼Œ ç”¨ä»–æ¥ç®¡ç†æ¶ˆæ¯æ“ä½œ

    print("\nğŸ¤– ä½ çš„AI Agentå·²ä¸Šçº¿ï¼è¯·è¾“å…¥æ‚¨çš„é—®é¢˜æˆ–è€…è¾“å…¥'NO' or 'é€€å‡º' ç»“æŸå¯¹è¯ã€‚")
    
    
    while True:
        user_input = input("\nğŸ’¬ ä½ : ").strip()
        if user_input.lower() in ['NO', 'é€€å‡º', 'exit', 'q']:
             print("ğŸ‘‹ AgentæœŸå¾…ä¸ä½ å†æ¬¡å¯¹è¯ï¼")
             break

        if not user_input:
            continue
    # æ„é€ æ¶ˆæ¯å¹¶è°ƒç”¨æ¨¡å‹
        try:
            memory_obj.add_to_memory('user', user_input)
            # 2. ã€å…³é”®ã€‘è·å–è½¬æ¢åçš„å®Œæ•´æ¶ˆæ¯å†å²ï¼ˆæ­¤æ—¶åŒ…å«åˆšå­˜çš„ç”¨æˆ·è¾“å…¥ï¼‰
            langchain_messages = get_memory_as_langchain_messages(memory_obj)
            print(f"ï¼ˆè°ƒè¯•ï¼‰è½¬æ¢åçš„æ¶ˆæ¯æ•°ï¼š{len(langchain_messages)}ï¼Œè§’è‰²åˆ†å¸ƒï¼š")

            for msg in langchain_messages:
                print(f"  - {type(msg).__name__}")

            # æ˜¾ç¤ºâ€œæ­£åœ¨æ€è€ƒâ€åŠ¨ç”»ï¼ˆæ©ç›–ç¬¬ä¸€è½®å»¶è¿Ÿï¼‰
            print("ğŸ¤– æ­£åœ¨æ€è€ƒ", end="", flush=True)
            for _ in range(3):
                time.sleep(0.1)
                print(".", end="", flush=True)
            print("\r", end="")  # æ¸…æ‰åŠ¨ç”»è¡Œï¼Œå‡†å¤‡æ‰“å°å›å¤

            invoke_start = time.time()
            # 4. ç”¨ invokeï¼ˆéæµå¼ï¼‰è·å–å®Œæ•´å“åº”ï¼Œä¾¿äºæ£€æŸ¥ æ¶ˆæ¯ä¸­æ˜¯å¦æœ‰tool_calls
            first_response = agent_brain.invoke(langchain_messages)
            # æŠŠç¬¬ä¸€è½®æ¨¡å‹è¾“å‡ºï¼ˆå¯èƒ½åŒ…å« tool_callsï¼‰åŠ å…¥å†å²
            
            
            full_response = ""  # ç”¨æ¥ç´¯ç§¯æœ€ç»ˆå›å¤å†…å®¹ï¼ˆåé¢å­˜è®°å¿†ï¼‰
            # print(f"ã€è°ƒè¯•ã€‘ç¬¬ä¸€è½®invokeè€—æ—¶: {time.time() - invoke_start:.2f}s")

            
            #åˆ¤æ–­ç¬¬ä¸€è½®å›ç­”ä¸­æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
            if hasattr(first_response,"tool_calls") and first_response.tool_calls:

                langchain_messages.append(first_response)  
                
                for tool_call in first_response.tool_calls:
                    tool_name = tool_call["name"]
                    tool_args = tool_call["args"]
                    print(f"\nğŸ› ï¸  æ­£åœ¨è°ƒç”¨å·¥å…·: {tool_name}({tool_args})")
                     # æ‰§è¡Œå¯¹åº”å·¥å…·
                    if tool_name == "domath":
                        result = calculator.invoke(tool_args)
                    elif tool_name == "search_Weather":
                        result = search_Weather.invoke(tool_args)
                    elif tool_name == "get_current_time":
                        result = get_current_time.invoke(tool_args)
                    else:
                        result = "æœªçŸ¥å·¥å…·"
                    print(f"âœ… å·¥å…·ç»“æœ: {result}")
                  
                    # åˆ›å»ºæ ‡å‡†çš„ToolMessageå¯¹è±¡
                    tool_message = ToolMessage(
                        content=str(result),          # å·¥å…·æ‰§è¡Œç»“æœ
                        tool_call_id=tool_call["id"], # å¿…é¡»ä¸è°ƒç”¨çš„idå¯¹åº”
                        name=tool_name                # å¯é€‰ï¼Œä½†å»ºè®®æä¾›
                    )
                    langchain_messages.append(tool_message)
                    memory_obj.add_to_memory('tool', f"{tool_name} å·¥å…·ç»“æœ: {result}")
                # 6. ç¬¬äºŒè½®è°ƒç”¨ï¼šæŠŠå·¥å…·ç»“æœå¡å›ï¼Œç”¨ stream æµå¼è¾“å‡ºæœ€ç»ˆå›å¤
                print("ğŸ¤– æœºå™¨äººå›å¤: ", end="", flush=True)
                for chunk in agent_brain.stream(langchain_messages):
                    if chunk.content:
                        print(chunk.content, end="", flush=True)
                        full_response += chunk.content
                print()  # ç»“æŸæ—¶æ¢è¡Œ
            else:

            #ä¿®æ”¹ä¸ºæµå¼æ‰“å°
                print("\nğŸ¤– æœºå™¨äººå›å¤: ", end="", flush=True)  # å¼€å§‹æ‰“å°ï¼Œä¸æ¢è¡Œ            
            # 3. ã€å…³é”®ä¿®æ”¹ã€‘ä½¿ç”¨æµå¼è°ƒç”¨
                for chunk in agent_brain.stream(langchain_messages):  # æ”¹æˆ .stream()
                    if chunk.content:  # æœ‰äº›chunkå¯èƒ½ä¸ºç©º
                        print(chunk.content, end="", flush=True)  # å®æ—¶æ‰“å°
                        full_response += chunk.content
            
            # 4. æµå¼ç»“æŸï¼Œæ¢è¡Œ + åˆ†éš”çº¿
                print("\n" + "-" * 40)
            
            # 5. å°†å®Œæ•´å›å¤å­˜å…¥è®°å¿†
            memory_obj.add_to_memory('assistant', full_response)
        
        
        
        except Exception as e:
            print(f"âš ï¸  å‡ºé”™äº†: {e}")


#ç”¨agentç®¡ç†ReAct ä¸éœ€è¦å†å­˜å‚¨å·¥å…·æ¶ˆæ¯ï¼Œ æ¶ˆæ¯åˆ—è¡¨é‡Œåªæœ‰ ç”¨æˆ· è·Ÿ AiåŠ©æ‰‹æ¶ˆæ¯
def newRun_chat_loop(memory_obj,agent):
    print("\nğŸ¤– LangGraph Agent å·²ä¸Šçº¿ï¼")
    
    while True:
        user_input = input("\nğŸ’¬ ä½ : ").strip()
        if user_input.lower() in ['é€€å‡º', 'q']:
            break
        
        memory_obj.add_to_memory('user', user_input)
        messages = get_memory_as_langchain_messages(memory_obj)
        
        # æ˜¾ç¤ºâ€œæ­£åœ¨æ€è€ƒâ€åŠ¨ç”»ï¼ˆæ©ç›–ç¬¬ä¸€è½®å»¶è¿Ÿï¼‰
        print("ğŸ¤– æ­£åœ¨æ€è€ƒ", end="", flush=True)
        for _ in range(3):
            time.sleep(0.1)
            print(".", end="", flush=True)
        print("\r", end="")  # æ¸…æ‰åŠ¨ç”»è¡Œï¼Œå‡†å¤‡æ‰“å°å›å¤
        full_response = ""

        print("\nã€ReAct æ€è€ƒé“¾å¼€å§‹ã€‘")
            
        
        for chunk in agent.stream({"messages": messages},stream_mode="updates",):
            for step, data in chunk.items():
                #æ¯ä¸€æ­¥çš„æ€è€ƒè¿‡ç¨‹
                # print(f"step: {step}")
                content_blocks = data['messages'][-1].content_blocks if data['messages'] else []
                # print(f"content: {content_blocks}")

                #æ¯ä¸€æ­¥çš„å›å¤
                for block in content_blocks:
                    if block['type'] == 'text':
                        text = block['text']
                        print(text, end="", flush=True)  # æµå¼æ‰“å°
                        #æ‹¼æ¥å›å¤ï¼Œæœ€åå­˜å…¥memoryList  åªå­˜æœ€ç»ˆç­”æ¡ˆ æ˜å¤©ä¼˜åŒ–
                        full_response += text

            
        print("\nã€ReAct æ€è€ƒé“¾ç»“æŸã€‘")
        print("-" * 40)
            
        memory_obj.add_to_memory('assistant', full_response)


# # 3. æ„é€ ä¸€ä¸ªç®€å•çš„ç”¨æˆ·æ¶ˆæ¯
# messages = [HumanMessage(content="æˆ‘è¦å­¦ai agentå¼€å‘ï¼Œè¯·å¸®æˆ‘å†™ä¸€ä¸ªå­¦ä¹ è®¡åˆ’")]

# # 4. è°ƒç”¨æ¨¡å‹å¹¶æ‰“å°å›å¤

if __name__ == "__main__":

    print("111111111")
# response = llm.invoke(messages)
# print("ğŸ’¬ æœºå™¨äººå›å¤ï¼š", response.content)


