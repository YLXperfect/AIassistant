'''
# å¯¼å…¥å¿…è¦çš„åº“
# ä½¿ç”¨æ–°ç‰ˆæ¨¡å—ç»“æ„
'''

from langchain_community.chat_models import ChatZhipuAI

from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
import os 
from memory import ConversationMemory  #  å€’å…¥å¯¹è¯ç®¡ç†ç±»


    
# 1. è®¾ç½®ä½ çš„API Key (è¿™é‡Œæ˜¯å”¯ä¸€éœ€è¦ä¿®æ”¹çš„åœ°æ–¹)

#day2 æŠŠæ­¥éª¤å°è£…æˆå‡½æ•°ï¼Œåœ¨mainé‡Œè°ƒç”¨
def get_api_key():
    """å®‰å…¨åœ°è·å–APIå¯†é’¥ã€‚å¦‚æœæœªè®¾ç½®ï¼Œåˆ™æŠ›å‡ºå¼‚å¸¸ã€‚"""
    zhipu_api_key = os.getenv("ZHIPUAI_API_KEY")
    if not zhipu_api_key:
        # æ”¹ä¸ºæŠ›å‡ºå¼‚å¸¸ï¼Œè€Œéç›´æ¥é€€å‡º
        raise ValueError("âŒ æœªæ‰¾åˆ°ç¯å¢ƒå˜é‡ ZHIPUAI_API_KEYã€‚è¯·åœ¨ç»ˆç«¯æ‰§è¡Œ: export ZHIPUAI_API_KEY='ä½ çš„å¯†é’¥'")
    return zhipu_api_key


def create_ai_agent(api_key):
    """æ ¹æ®ç»™å®šçš„APIå¯†é’¥ï¼Œåˆ›å»ºå¹¶è¿”å›ä¸€ä¸ªAI Agentå®ä¾‹ï¼ˆæ¨¡å‹ï¼‰ã€‚"""
    print("ğŸ§  æ­£åœ¨åˆå§‹åŒ–AI Agent...")
    llm = ChatZhipuAI(
        model="glm-4-flash",
        temperature=0.1,
        api_key=api_key,
    )
    return llm

# åœ¨è®°å¿†æ¨¡å—éƒ¨åˆ†ï¼Œæ·»åŠ ä»¥ä¸‹å‡½æ•°ï¼ˆæ”¾åœ¨ get_memory å‡½æ•°åé¢å³å¯ï¼‰  æ·»åŠ å‚æ•°memory_objï¼Œ ç”¨ä»–æ¥ç®¡ç†æ¶ˆæ¯æ“ä½œ
def get_memory_as_langchain_messages(memory_obj):
    """å°†å†…éƒ¨è®°å¿†æ ¼å¼è½¬æ¢ä¸ºLangChainçš„Messageå¯¹è±¡åˆ—è¡¨"""
    langchain_messages = []
    for msg in memory_obj.getAllMemoryList():  
        if msg["role"] == "user":
            langchain_messages.append(HumanMessage(content=msg["content"]))
        elif msg["role"] == "assistant":
            langchain_messages.append(AIMessage(content=msg["content"]))
        elif msg["role"] == "system":
            langchain_messages.append(SystemMessage(content=msg["content"]))
    return langchain_messages
    #è¿”å›çš„æ˜¯ä¸€ä¸ªå…¨æ˜¯langchianå¯¹è±¡çš„æ¶ˆæ¯åˆ—è¡¨ï¼Œå°†æ•´ä¸ªå¯¹è¯å†…å®¹å‘é€ç»™æ¨¡å‹ï¼Œ ä½¿å¾—æ¨¡å‹æœ‰è®°å¿†

def run_chat_loop(agent_brain,memory_obj): #æ·»åŠ å‚æ•°memory_objï¼Œ ç”¨ä»–æ¥ç®¡ç†æ¶ˆæ¯æ“ä½œ

    print("\nğŸ¤– ä½ çš„AI Agentå·²ä¸Šçº¿ï¼è¯·è¾“å…¥æ‚¨çš„é—®é¢˜æˆ–è€…è¾“å…¥'NO' or 'é€€å‡º' ç»“æŸå¯¹è¯ã€‚")
    
    
    while True:
        user_input = input("\nğŸ’¬ ä½ : ").strip()
        if user_input.lower() in ['NO', 'é€€å‡º', 'exit', 'q']:
             print("ğŸ‘‹ AgentæœŸå¾…ä¸ä½ å†æ¬¡å¯¹è¯ï¼")
             break

        if not user_input:
            continue
    # æ„é€ æ¶ˆæ¯å¹¶è°ƒç”¨æ¨¡å‹

        try:
            memory_obj.add_to_memory('user', user_input)
            # 2. ã€å…³é”®ã€‘è·å–è½¬æ¢åçš„å®Œæ•´æ¶ˆæ¯å†å²ï¼ˆæ­¤æ—¶åŒ…å«åˆšå­˜çš„ç”¨æˆ·è¾“å…¥ï¼‰
            langchain_messages = get_memory_as_langchain_messages(memory_obj)
            print(f"ï¼ˆè°ƒè¯•ï¼‰å‘é€ç»™æ¨¡å‹çš„æ¶ˆæ¯ï¼š{(langchain_messages)} ")  # è°ƒè¯•è¡Œ
                # 3. è°ƒç”¨æ¨¡å‹
            response = agent_brain.invoke(langchain_messages)
    
             # 4. å°†AIå›å¤å­˜å…¥è®°å¿†
            memory_obj.add_to_memory('assistant', response.content)
        
        # æ‰“å°Agentå›å¤
            print(f"\nğŸ¤– ğŸ’¬ æœºå™¨äººå›å¤: {response.content}")
            print("-" * 40)
        
        except Exception as e:
            print(f"âš ï¸  å‡ºé”™äº†: {e}")
            

# # 3. æ„é€ ä¸€ä¸ªç®€å•çš„ç”¨æˆ·æ¶ˆæ¯
# messages = [HumanMessage(content="æˆ‘è¦å­¦ai agentå¼€å‘ï¼Œè¯·å¸®æˆ‘å†™ä¸€ä¸ªå­¦ä¹ è®¡åˆ’")]

# # 4. è°ƒç”¨æ¨¡å‹å¹¶æ‰“å°å›å¤

if __name__ == "__main__":

    print("111111111")
# response = llm.invoke(messages)
# print("ğŸ’¬ æœºå™¨äººå›å¤ï¼š", response.content)


