'''
# å¯¼å…¥å¿…è¦çš„åº“
# ä½¿ç”¨æ–°ç‰ˆæ¨¡å—ç»“æ„
'''

from langchain_community.chat_models import ChatZhipuAI


from langgraph.prebuilt import create_react_agent

from langchain.agents import create_react_agent, AgentExecutor
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage,ToolMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

import os 
from memory import ConversationMemory  #  å¯¼å…¥å¯¹è¯ç®¡ç†ç±»

from tools import calculator, search_Weather,get_current_time #å¯¼å…¥å·¥å…·
import time


    
# 1. è®¾ç½®ä½ çš„API Key (è¿™é‡Œæ˜¯å”¯ä¸€éœ€è¦ä¿®æ”¹çš„åœ°æ–¹)

#day2 æŠŠæ­¥éª¤å°è£…æˆå‡½æ•°ï¼Œåœ¨mainé‡Œè°ƒç”¨
def get_api_key():
    """å®‰å…¨åœ°è·å–APIå¯†é’¥ã€‚å¦‚æœæœªè®¾ç½®ï¼Œåˆ™æŠ›å‡ºå¼‚å¸¸ã€‚"""
    zhipu_api_key = os.getenv("ZHIPUAI_API_KEY")
    if not zhipu_api_key:
        # æ”¹ä¸ºæŠ›å‡ºå¼‚å¸¸ï¼Œè€Œéç›´æ¥é€€å‡º
        raise ValueError("âŒ æœªæ‰¾åˆ°ç¯å¢ƒå˜é‡ ZHIPUAI_API_KEYã€‚è¯·åœ¨ç»ˆç«¯æ‰§è¡Œ: export ZHIPUAI_API_KEY='ä½ çš„å¯†é’¥'")
    return zhipu_api_key


def create_ai_agent_executor(api_key):
    print("ğŸ§  æ­£åœ¨åˆå§‹åŒ– ReAct AgentExecutor...")
    llm = ChatZhipuAI(
        model="glm-4-flash",          # æ¨èç”¨ flashï¼Œæ›´å¿«
        temperature=0.7,              # ç¨é«˜ä¸€ç‚¹ï¼Œæ›´å®¹æ˜“è°ƒç”¨å·¥å…·
        api_key=api_key,
    )
    
    tools = [calculator, search_Weather, get_current_time]
    
    # æœ¬åœ°æ¨¡æ‹Ÿ react-chat æç¤ºè¯ï¼ˆå®˜æ–¹æ¨èæ›¿ä»£ hub.pullï¼‰
    prompt = ChatPromptTemplate.from_messages([
        ("system", """ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„AIåŠ©æ‰‹ï¼Œèƒ½ä½¿ç”¨å·¥å…·è§£å†³é—®é¢˜ã€‚
        è¯·ä¸¥æ ¼æŒ‰ç…§ ReAct æ ¼å¼æ€è€ƒï¼š
        - Thought: å…ˆæ€è€ƒä¸‹ä¸€æ­¥è¯¥åšä»€ä¹ˆ
        - Action: å¦‚æœéœ€è¦å·¥å…·ï¼Œå°±è¾“å‡ºå·¥å…·è°ƒç”¨
        - Observation: å·¥å…·è¿”å›ç»“æœåç»§ç»­æ€è€ƒ
        - Final Answer: æœ€ç»ˆç»™å‡ºç”¨æˆ·å¯è§çš„å›ç­”"""),
        MessagesPlaceholder("chat_history"),
        ("human", "{input}"),
        MessagesPlaceholder("agent_scratchpad"),
    ])
    
    # åˆ›å»º ReAct Agent
    agent = create_react_agent(llm, tools, prompt)
    
    # åˆ›å»ºæ‰§è¡Œå™¨
    agent_executor = AgentExecutor(
        agent=agent,
        tools=tools,
        verbose=True,                  # å¿…é¡»å¼€ï¼çœ‹æ€è€ƒé“¾
        handle_parsing_errors=True,    # è‡ªåŠ¨å¤„ç†æ ¼å¼é”™è¯¯
        max_iterations=10,             # é˜²æ­»å¾ªç¯
    )
    
    return agent_executor


def create_ai_agent(api_key):
    
    """æ ¹æ®ç»™å®šçš„APIå¯†é’¥ï¼Œåˆ›å»ºå¹¶è¿”å›ä¸€ä¸ªAI Agentå®ä¾‹ï¼ˆæ¨¡å‹ï¼‰ã€‚éœ€è¦æ‰‹åŠ¨ç®¡ç†ReActæµç¨‹"""
    print("ğŸ§  æ­£åœ¨åˆå§‹åŒ–AI Agent...")
    llm = ChatZhipuAI(
        model="glm-4",
        temperature=0.1,
        streaming=True,
        api_key=api_key,
    )
    tools = [calculator, search_Weather,get_current_time]  
    llm_with_tools = llm.bind_tools(tools)  #æ·»åŠ å¹¶ç»‘å®šå·¥å…·ç»™æ¨¡å‹
    return llm_with_tools
    '''
    
    '''
    

# åœ¨è®°å¿†æ¨¡å—éƒ¨åˆ†ï¼Œæ·»åŠ ä»¥ä¸‹å‡½æ•°ï¼ˆæ”¾åœ¨ get_memory å‡½æ•°åé¢å³å¯ï¼‰  æ·»åŠ å‚æ•°memory_objï¼Œ ç”¨ä»–æ¥ç®¡ç†æ¶ˆæ¯æ“ä½œ
def get_memory_as_langchain_messages(memory_obj):
    """å°†å†…éƒ¨è®°å¿†æ ¼å¼è½¬æ¢ä¸ºLangChainçš„Messageå¯¹è±¡åˆ—è¡¨"""
    langchain_messages = []
    for msg in memory_obj.getAllMemoryList():  
        if msg["role"] == "user":
            langchain_messages.append(HumanMessage(content=msg["content"]))
        elif msg["role"] == "assistant":
            langchain_messages.append(AIMessage(content=msg["content"]))
        elif msg["role"] == "system":
            langchain_messages.append(SystemMessage(content=msg["content"]))
        elif msg["role"] == "tool":
            # æ³¨æ„ï¼šä½ çš„å†…å­˜ä¸­å­˜å‚¨çš„æ˜¯å­—å…¸ï¼Œéœ€è¦æå–ä¿¡æ¯æ„é€ ToolMessage
            # å‡è®¾ä½ å­˜å‚¨æ—¶æ ¼å¼æ˜¯ï¼š{"role": "tool", "content": "...", "name": "...", "tool_call_id": "..."}
            # ä½ éœ€è¦æ ¹æ®å®é™…å­˜å‚¨çš„å­—æ®µæ¥è°ƒæ•´
            tool_message = ToolMessage(
                content=msg.get("content", ""),
                name=msg.get("name", ""),  
                tool_call_id=msg.get("tool_call_id", "")  
            )
            langchain_messages.append(tool_message)
    return langchain_messages
    #è¿”å›çš„æ˜¯ä¸€ä¸ªå…¨æ˜¯langchianå¯¹è±¡çš„æ¶ˆæ¯åˆ—è¡¨ï¼Œå°†æ•´ä¸ªå¯¹è¯å†…å®¹å‘é€ç»™æ¨¡å‹ï¼Œ ä½¿å¾—æ¨¡å‹æœ‰è®°å¿†



def run_chat_loop(agent_executor, memory_obj):
    print("\nğŸ¤– AgentExecutor å·²ä¸Šçº¿ï¼è¾“å…¥'é€€å‡º'ç»“æŸã€‚")
    
    while True:
        user_input = input("\nğŸ’¬ ä½ : ").strip()
        if user_input.lower() in ['é€€å‡º', 'exit', 'q']:
            break
        if not user_input:
            continue
        
        try:
            memory_obj.add_to_memory('user', user_input)
            chat_history = get_memory_as_langchain_messages(memory_obj)[:-1]
            
            print("ğŸ¤– æ­£åœ¨æ€è€ƒ......")
            
            full_response = ""
            for chunk in agent_executor.stream({
                "input": user_input,
                "chat_history": chat_history
            }):
                if "output" in chunk:
                    content = chunk["output"]
                    print(content, end="", flush=True)
                    full_response += content
            
            print("\n" + "-" * 40)
            memory_obj.add_to_memory('assistant', full_response)
            
        except Exception as e:
            print(f"âš ï¸ é”™è¯¯: {e}")

def run_chat_loop(agent_brain,memory_obj): #æ·»åŠ å‚æ•°memory_objï¼Œ ç”¨ä»–æ¥ç®¡ç†æ¶ˆæ¯æ“ä½œ

    print("\nğŸ¤– ä½ çš„AI Agentå·²ä¸Šçº¿ï¼è¯·è¾“å…¥æ‚¨çš„é—®é¢˜æˆ–è€…è¾“å…¥'NO' or 'é€€å‡º' ç»“æŸå¯¹è¯ã€‚")
    
    
    while True:
        user_input = input("\nğŸ’¬ ä½ : ").strip()
        if user_input.lower() in ['NO', 'é€€å‡º', 'exit', 'q']:
             print("ğŸ‘‹ AgentæœŸå¾…ä¸ä½ å†æ¬¡å¯¹è¯ï¼")
             break

        if not user_input:
            continue
    # æ„é€ æ¶ˆæ¯å¹¶è°ƒç”¨æ¨¡å‹

        try:
            start_time = time.time()  # æœ¬è½®æ€»è®¡æ—¶å¼€å§‹

            memory_obj.add_to_memory('user', user_input)
            # 2. ã€å…³é”®ã€‘è·å–è½¬æ¢åçš„å®Œæ•´æ¶ˆæ¯å†å²ï¼ˆæ­¤æ—¶åŒ…å«åˆšå­˜çš„ç”¨æˆ·è¾“å…¥ï¼‰
            langchain_messages = get_memory_as_langchain_messages(memory_obj)
            print(f"ï¼ˆè°ƒè¯•ï¼‰è½¬æ¢åçš„æ¶ˆæ¯æ•°ï¼š{len(langchain_messages)}ï¼Œè§’è‰²åˆ†å¸ƒï¼š")
            print(f"ã€è°ƒè¯•ã€‘å‡†å¤‡æ¶ˆæ¯è€—æ—¶: {time.time() - start_time:.2f}s (å†å²{len(langchain_messages)}æ¡)")

            for msg in langchain_messages:
                print(f"  - {type(msg).__name__}")

            # print(f"ï¼ˆè°ƒè¯•ï¼‰å‘é€ç»™æ¨¡å‹çš„æ¶ˆæ¯ï¼š{(langchain_messages)} ")  # è°ƒè¯•è¡Œ
            #     # 3. è°ƒç”¨æ¨¡å‹
            # response = agent_brain.invoke(langchain_messages)  ç­‰ç­”æ¡ˆå…¨éƒ¨è·å–åˆ°ï¼Œæ‰å¼€å§‹æ‰“å° 
    
            #  # 4. å°†AIå›å¤å­˜å…¥è®°å¿†
            # memory_obj.add_to_memory('assistant', response.content)
            # æ‰“å°Agentå›å¤
            # print(f"\nğŸ¤– ğŸ’¬ æœºå™¨äººå›å¤: {response.content}")
            # print("-" * 40)




            # æ˜¾ç¤ºâ€œæ­£åœ¨æ€è€ƒâ€åŠ¨ç”»ï¼ˆæ©ç›–ç¬¬ä¸€è½®å»¶è¿Ÿï¼‰
            print("ğŸ¤– æ­£åœ¨æ€è€ƒ", end="", flush=True)
            for _ in range(3):
                time.sleep(0.1)
                print(".", end="", flush=True)
            print("\r", end="")  # æ¸…æ‰åŠ¨ç”»è¡Œï¼Œå‡†å¤‡æ‰“å°å›å¤

            invoke_start = time.time()
            # 4. ç”¨ invokeï¼ˆéæµå¼ï¼‰è·å–å®Œæ•´å“åº”ï¼Œä¾¿äºæ£€æŸ¥ æ¶ˆæ¯ä¸­æ˜¯å¦æœ‰tool_calls
            first_response = agent_brain.invoke(langchain_messages)
            # æŠŠç¬¬ä¸€è½®æ¨¡å‹è¾“å‡ºï¼ˆå¯èƒ½åŒ…å« tool_callsï¼‰åŠ å…¥å†å²
            
            
            full_response = ""  # ç”¨æ¥ç´¯ç§¯æœ€ç»ˆå›å¤å†…å®¹ï¼ˆåé¢å­˜è®°å¿†ï¼‰
            # print(f"ã€è°ƒè¯•ã€‘ç¬¬ä¸€è½®invokeè€—æ—¶: {time.time() - invoke_start:.2f}s")

            
            #åˆ¤æ–­ç¬¬ä¸€è½®å›ç­”ä¸­æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
            if hasattr(first_response,"tool_calls") and first_response.tool_calls:

                langchain_messages.append(first_response)  
                
                for tool_call in first_response.tool_calls:
                    tool_name = tool_call["name"]
                    tool_args = tool_call["args"]
                    print(f"\nğŸ› ï¸  æ­£åœ¨è°ƒç”¨å·¥å…·: {tool_name}({tool_args})")
                     # æ‰§è¡Œå¯¹åº”å·¥å…·
                    if tool_name == "domath":
                        result = calculator.invoke(tool_args)
                    elif tool_name == "search_Weather":
                        result = search_Weather.invoke(tool_args)
                    elif tool_name == "get_current_time":
                        result = get_current_time.invoke(tool_args)
                    else:
                        result = "æœªçŸ¥å·¥å…·"
                    print(f"âœ… å·¥å…·ç»“æœ: {result}")
                  
                    # åˆ›å»ºæ ‡å‡†çš„ToolMessageå¯¹è±¡
                    tool_message = ToolMessage(
                        content=str(result),          # å·¥å…·æ‰§è¡Œç»“æœ
                        tool_call_id=tool_call["id"], # å¿…é¡»ä¸è°ƒç”¨çš„idå¯¹åº”
                        name=tool_name                # å¯é€‰ï¼Œä½†å»ºè®®æä¾›
                    )
                    langchain_messages.append(tool_message)
                    memory_obj.add_to_memory('tool', f"{tool_name} å·¥å…·ç»“æœ: {result}")
                # 6. ç¬¬äºŒè½®è°ƒç”¨ï¼šæŠŠå·¥å…·ç»“æœå¡å›ï¼Œç”¨ stream æµå¼è¾“å‡ºæœ€ç»ˆå›å¤
                print("ğŸ¤– æœºå™¨äººå›å¤: ", end="", flush=True)
                for chunk in agent_brain.stream(langchain_messages):
                    if chunk.content:
                        print(chunk.content, end="", flush=True)
                        full_response += chunk.content
                print()  # ç»“æŸæ—¶æ¢è¡Œ
            else:

            #ä¿®æ”¹ä¸ºæµå¼æ‰“å°
                print("\nğŸ¤– æœºå™¨äººå›å¤: ", end="", flush=True)  # å¼€å§‹æ‰“å°ï¼Œä¸æ¢è¡Œ            
            # 3. ã€å…³é”®ä¿®æ”¹ã€‘ä½¿ç”¨æµå¼è°ƒç”¨
                for chunk in agent_brain.stream(langchain_messages):  # æ”¹æˆ .stream()
                    if chunk.content:  # æœ‰äº›chunkå¯èƒ½ä¸ºç©º
                        print(chunk.content, end="", flush=True)  # å®æ—¶æ‰“å°
                        full_response += chunk.content
            
            # 4. æµå¼ç»“æŸï¼Œæ¢è¡Œ + åˆ†éš”çº¿
                print("\n" + "-" * 40)
            
            # 5. å°†å®Œæ•´å›å¤å­˜å…¥è®°å¿†
            memory_obj.add_to_memory('assistant', full_response)
        
        
        
        except Exception as e:
            print(f"âš ï¸  å‡ºé”™äº†: {e}")
            

# # 3. æ„é€ ä¸€ä¸ªç®€å•çš„ç”¨æˆ·æ¶ˆæ¯
# messages = [HumanMessage(content="æˆ‘è¦å­¦ai agentå¼€å‘ï¼Œè¯·å¸®æˆ‘å†™ä¸€ä¸ªå­¦ä¹ è®¡åˆ’")]

# # 4. è°ƒç”¨æ¨¡å‹å¹¶æ‰“å°å›å¤

if __name__ == "__main__":

    print("111111111")
# response = llm.invoke(messages)
# print("ğŸ’¬ æœºå™¨äººå›å¤ï¼š", response.content)


